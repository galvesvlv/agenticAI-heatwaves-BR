{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU-Asx9wJUYL"
      },
      "source": [
        "# Global Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrfXagWBJXPw"
      },
      "source": [
        "## Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-MDxes0JYS7",
        "outputId": "f0c1ef00-6426-4675-bb7c-607022f01fa5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN86Hs19Km_W"
      },
      "source": [
        "## config module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxGmQZAWWZh3",
        "outputId": "02a8c729-0753-4cb7-cd1a-f64b379dfc5b"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20Ha1hcSJmw9",
        "outputId": "e747dbc7-74e3-42b7-9fbb-f3de37b57f8f"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import os\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Global Paths\n",
        "ROOT_DIR  = Path(\"/content/drive/MyDrive/Pós-Graduações/Computer_Vision_Master/Materias/EII/Final_Project\")\n",
        "\n",
        "# Paths\n",
        "DATASET_PATH = ROOT_DIR / \"WMO_heatwave_conditions_1961-present.nc\"\n",
        "\n",
        "# Global variables\n",
        "HISTORICAL_PERIOD = (\"1961-01-01\", \"1990-12-31\")\n",
        "\n",
        "# Config Device\n",
        "DEVICE = (\n",
        "          \"cuda\"\n",
        "          if torch.cuda.is_available()\n",
        "          else \"mps\"\n",
        "          if torch.backends.mps.is_available()\n",
        "          else \"cpu\"\n",
        "          )\n",
        "\n",
        "print(f\"GPU is available? {torch.cuda.is_available()}\")\n",
        "\n",
        "print(f\"Using {DEVICE} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz4dqkypKpa9"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY3C4-CmqXIC"
      },
      "source": [
        "## Exploration Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "1dbvBbzJKrRt",
        "outputId": "1873338a-e294-4d5a-a4cf-89917b69b884"
      },
      "outputs": [],
      "source": [
        "ds = xr.open_dataset(DATASET_PATH)\n",
        "ds = ds.isel(time=slice(None, -1))\n",
        "ds.HWC.mean(dim='time').plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDfGSFPMoY-W",
        "outputId": "ac228417-d21d-4071-add6-15789f55c0a0"
      },
      "outputs": [],
      "source": [
        "ds.dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "yZ3seIOKoJVT",
        "outputId": "6d3aed3b-7edf-4aac-ee7a-e651dc4482b4"
      },
      "outputs": [],
      "source": [
        "ds.time.tail(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LAVkgv9lUVu"
      },
      "source": [
        "## preprocessing module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DZrkdlfqlKs"
      },
      "outputs": [],
      "source": [
        "class ZScoreNormalizer:\n",
        "    \"\"\"\n",
        "    Z-score normalizer for spatiotemporal tensors.\n",
        "\n",
        "    This class computes a global mean and standard deviation from the\n",
        "    training data and applies standardization to inputs and targets.\n",
        "    It also supports inverse transformation back to physical units.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, eps=1e-8):\n",
        "        \"\"\"\n",
        "        Initialize the normalizer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        eps : float, optional\n",
        "            Small constant added to the standard deviation to avoid\n",
        "            division by zero. Default is 1e-8.\n",
        "        \"\"\"\n",
        "\n",
        "        self.mu = None\n",
        "        self.sigma = None\n",
        "        self.eps = eps\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Compute mean and standard deviation from training data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : torch.Tensor\n",
        "            Input tensor used for fitting the normalizer.\n",
        "            Expected shape: (N, T, C, H, W) or compatible.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : ZScoreNormalizer\n",
        "            Fitted normalizer.\n",
        "        \"\"\"\n",
        "\n",
        "        self.mu = X.mean()\n",
        "        self.sigma = X.std() + self.eps\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Apply z-score normalization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : torch.Tensor\n",
        "            Input tensor to be normalized.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Normalized tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.mu is None or self.sigma is None:\n",
        "            raise RuntimeError(\"Normalizer must be fitted first.\")\n",
        "\n",
        "        return (X - self.mu) / self.sigma\n",
        "\n",
        "    def fit_transform(self, X):\n",
        "        \"\"\"\n",
        "        Fit the normalizer and apply normalization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : torch.Tensor\n",
        "            Input tensor used for fitting and transformation.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Normalized tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n",
        "\n",
        "    def inverse_transform(self, X):\n",
        "        \"\"\"\n",
        "        Convert normalized values back to the original physical scale.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : torch.Tensor\n",
        "            Normalized tensor.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Tensor in the original physical units.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.mu is None or self.sigma is None:\n",
        "            raise RuntimeError(\"Normalizer must be fitted first.\")\n",
        "        return X * self.sigma + self.mu\n",
        "\n",
        "\n",
        "class DHWDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset for Deep Heatwave (DHW) prediction.\n",
        "\n",
        "    Each sample consists of a temporal sequence of spatial fields\n",
        "    and the corresponding target field at the next time step.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        \"\"\"\n",
        "        Initialize the dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : torch.Tensor\n",
        "            Input tensor with shape (N, T, C, H, W),\n",
        "            where N is the number of samples and T is the sequence length.\n",
        "        y : torch.Tensor\n",
        "            Target tensor with shape (N, C, H, W).\n",
        "        \"\"\"\n",
        "\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Return the number of samples in the dataset.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieve a single sample from the dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        idx : int\n",
        "            Index of the sample.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple\n",
        "            (X_i, y_i), where:\n",
        "            - X_i has shape (T, C, H, W)\n",
        "            - y_i has shape (C, H, W)\n",
        "        \"\"\"\n",
        "\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "\n",
        "def make_sequences(data, seq_len=12):\n",
        "    \"\"\"\n",
        "    Create input-output sequences for supervised temporal learning.\n",
        "\n",
        "    Given a time-ordered spatial dataset, this function builds\n",
        "    sliding windows of length `seq_len` as inputs and the subsequent\n",
        "    time step as the target.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : numpy.ndarray\n",
        "        Input array with shape (time, latitude, longitude).\n",
        "    seq_len : int, optional\n",
        "        Length of the input temporal sequence. Default is 12.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : numpy.ndarray\n",
        "        Input sequences with shape (N, seq_len, 1, H, W).\n",
        "    y : numpy.ndarray\n",
        "        Target fields with shape (N, 1, H, W).\n",
        "    \"\"\"\n",
        "\n",
        "    X, y = [], []\n",
        "\n",
        "    for t in range(seq_len, len(data)):\n",
        "        X.append(data[t-seq_len:t])  # 12 months\n",
        "        y.append(data[t])            # next month\n",
        "\n",
        "    X = np.array(X)[:, :, None, :, :]\n",
        "    y = np.array(y)[:, None, :, :]\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g_5t5Bgre5M"
      },
      "source": [
        "## model module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgEIcXHLriIl"
      },
      "outputs": [],
      "source": [
        "class TemporalUnetTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Spatiotemporal U-Net with a temporal Transformer at the bottleneck.\n",
        "\n",
        "    This model combines a convolutional U-Net encoder–decoder architecture\n",
        "    with a Transformer-based temporal module applied at the deepest spatial\n",
        "    representation. The encoder is applied independently to each time step,\n",
        "    while temporal dependencies are learned at the bottleneck level using\n",
        "    self-attention.\n",
        "\n",
        "    The output is a spatial field corresponding to the prediction at the\n",
        "    next time step.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "                 self,\n",
        "                 in_channels=1,\n",
        "                 out_channels=1,\n",
        "                 encoder_name=\"resnet18\",\n",
        "                 encoder_weights=None,\n",
        "                 n_heads=4,\n",
        "                 num_layers=1,\n",
        "                 ):\n",
        "        \"\"\"\n",
        "        Initialize the Temporal U-Net Transformer model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        in_channels : int, optional\n",
        "            Number of input channels per time step. Default is 1.\n",
        "        out_channels : int, optional\n",
        "            Number of output channels. Default is 1.\n",
        "        encoder_name : str, optional\n",
        "            Name of the encoder backbone used in the U-Net architecture.\n",
        "            Must be compatible with `segmentation_models_pytorch`.\n",
        "            Default is \"resnet34\".\n",
        "        encoder_weights : str or None, optional\n",
        "            Pretrained weights for the encoder backbone.\n",
        "            Common options are \"imagenet\" or None. Default is None.\n",
        "        n_heads : int, optional\n",
        "            Number of attention heads in the temporal Transformer.\n",
        "            Default is 8.\n",
        "        num_layers : int, optional\n",
        "            Number of Transformer encoder layers.\n",
        "            Default is 2.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # U-Net backbone\n",
        "        self.unet = smp.Unet(\n",
        "                             encoder_name=encoder_name,\n",
        "                             encoder_weights=encoder_weights,\n",
        "                             in_channels=in_channels,\n",
        "                             classes=out_channels,\n",
        "                             activation=None,\n",
        "                             )\n",
        "\n",
        "        self.encoder = self.unet.encoder\n",
        "        self.decoder = self.unet.decoder\n",
        "        self.head = self.unet.segmentation_head\n",
        "\n",
        "        # Number of channels at the bottleneck (deepest encoder level)\n",
        "        bottleneck_channels = self.encoder.out_channels[-1]\n",
        "\n",
        "        # Temporal Transformer\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "                                                   d_model=bottleneck_channels,\n",
        "                                                   nhead=n_heads,\n",
        "                                                   dim_feedforward=4 * bottleneck_channels,\n",
        "                                                   batch_first=True,\n",
        "                                                   dropout=0.1,\n",
        "                                                   )\n",
        "\n",
        "        self.temporal_transformer = nn.TransformerEncoder(\n",
        "                                                          encoder_layer,\n",
        "                                                          num_layers=num_layers,\n",
        "                                                          )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            Input tensor with shape (B, T, C, H, W), where:\n",
        "            - B is the batch size\n",
        "            - T is the number of time steps\n",
        "            - C is the number of input channels\n",
        "            - H is the height of the spatial grid\n",
        "            - W is the width of the spatial grid\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Output tensor with shape (B, out_channels, H, W),\n",
        "            representing the predicted spatial field at the next time step.\n",
        "        \"\"\"\n",
        "\n",
        "        B, T, _, H, W = x.shape\n",
        "\n",
        "        bottlenecks = []\n",
        "        skips_all = []\n",
        "\n",
        "        # Encoder applied per time step\n",
        "        for t in range(T):\n",
        "            feats = self.encoder(x[:, t])   # multi-scale feature maps\n",
        "            skips_all.append(feats[:-1])    # skip connections\n",
        "            bottlenecks.append(feats[-1])   # bottleneck features (B, C, h, w)\n",
        "\n",
        "        # Stack bottleneck features along the temporal dimension\n",
        "        # Shape: (B, T, C, h, w)\n",
        "        Z = torch.stack(bottlenecks, dim=1)\n",
        "\n",
        "        B, T, C, h, w = Z.shape\n",
        "\n",
        "        # Temporal Transformer\n",
        "        # Each spatial location is treated as a temporal sequence\n",
        "        Z = Z.permute(0, 3, 4, 1, 2)      # (B, h, w, T, C)\n",
        "        Z = Z.reshape(B * h * w, T, C)    # (B*h*w, T, C)\n",
        "\n",
        "        Z = self.temporal_transformer(Z)  # (B*h*w, T, C)\n",
        "        Z = Z[:, -1]                      # last temporal step\n",
        "\n",
        "        # Restore spatial structure\n",
        "        Z = Z.reshape(B, h, w, C)\n",
        "        Z = Z.permute(0, 3, 1, 2)         # (B, C, h, w)\n",
        "\n",
        "        # U-Net decoder\n",
        "        # Uses skip connections from the last time step\n",
        "        features = skips_all[-1] + [Z]\n",
        "\n",
        "        y = self.decoder(features)\n",
        "        y = self.head(y)\n",
        "\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vx40bXqr257"
      },
      "source": [
        "## train_eval_loop module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7InJjg6Pr5Je"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
        "    \"\"\"\n",
        "    Execute one training epoch.\n",
        "\n",
        "    This function performs a full pass over the training dataset, computing\n",
        "    forward and backward passes, updating model parameters, and accumulating\n",
        "    the training loss.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataloader : torch.utils.data.DataLoader\n",
        "        DataLoader providing batches of training data. Each batch must return\n",
        "        a tuple (X, y), where:\n",
        "        - X has shape (B, T, C, H, W)\n",
        "        - y has shape (B, C, H, W)\n",
        "    model : torch.nn.Module\n",
        "        Neural network model to be trained.\n",
        "    loss_fn : callable\n",
        "        Loss function used for optimization (e.g., torch.nn.MSELoss).\n",
        "    optimizer : torch.optim.Optimizer\n",
        "        Optimizer used to update model parameters.\n",
        "    device : torch.device or str\n",
        "        Device on which computations are performed (\"cpu\", \"cuda\", or \"mps\").\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        Average training loss (MSE) over the entire epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    size = len(dataloader.dataset)\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Forward\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            current = batch * X.size(0)\n",
        "            print(f\"batch {batch:4d} | loss {loss.item():.6f}\")\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "def eval_loop(dataloader, model, loss_fn, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on a validation or test dataset.\n",
        "\n",
        "    This function runs the model in evaluation mode, disables gradient\n",
        "    computation, and computes the mean squared error (MSE) and root mean\n",
        "    squared error (RMSE) over the provided dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataloader : torch.utils.data.DataLoader\n",
        "        DataLoader providing batches of validation or test data. Each batch\n",
        "        must return a tuple (X, y), where:\n",
        "        - X has shape (B, T, C, H, W)\n",
        "        - y has shape (B, C, H, W)\n",
        "    model : torch.nn.Module\n",
        "        Trained neural network model to be evaluated.\n",
        "    loss_fn : callable\n",
        "        Loss function used for evaluation (e.g., torch.nn.MSELoss).\n",
        "    device : torch.device or str\n",
        "        Device on which computations are performed (\"cpu\", \"cuda\", or \"mps\").\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    avg_mse : float\n",
        "        Mean squared error averaged over all batches.\n",
        "    rmse : float\n",
        "        Root mean squared error computed from the averaged MSE.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    total_mse = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            pred = model(X)\n",
        "            mse = loss_fn(pred, y)\n",
        "\n",
        "            total_mse += mse.item()\n",
        "\n",
        "    avg_mse = total_mse / len(dataloader)\n",
        "    rmse = np.sqrt(avg_mse)\n",
        "\n",
        "    return avg_mse, rmse\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_1kntWgtM5F"
      },
      "source": [
        "## main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgxxyguOlWCj"
      },
      "outputs": [],
      "source": [
        "# Heatwave conditions\n",
        "dhw = ds.HWC\n",
        "\n",
        "# Monthly Climatology (1961–1990)\n",
        "clim = dhw.sel(time=slice(HISTORICAL_PERIOD[0], HISTORICAL_PERIOD[1])).groupby(\"time.month\").mean(\"time\")\n",
        "\n",
        "# Monthly Anomalies\n",
        "dhw_anom = dhw.groupby(\"time.month\") - clim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhYzkdUnkq4G"
      },
      "outputs": [],
      "source": [
        "dhw_np = dhw_anom.transpose(\"time\", \"latitude\", \"longitude\").values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Olz_QBdPnwQA",
        "outputId": "413ab909-72de-4fc1-f0b0-22279c7d4443"
      },
      "outputs": [],
      "source": [
        "dhw_np.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbVVm2FJn2Ot"
      },
      "outputs": [],
      "source": [
        "# Formating X, y for Torch Datasets\n",
        "X, y = make_sequences(dhw_np, seq_len=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMLIxYcxoF9d",
        "outputId": "842840d2-9597-4baf-e2de-9f3f54fbf7a4"
      },
      "outputs": [],
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N45i5zoJoL9P"
      },
      "outputs": [],
      "source": [
        "X = torch.from_numpy(X).float()\n",
        "y = torch.from_numpy(y).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l5DP4GBonI2"
      },
      "outputs": [],
      "source": [
        "train_end_norm = int(0.8 * X.shape[0])\n",
        "\n",
        "normalizer = ZScoreNormalizer()\n",
        "\n",
        "X[:train_end_norm] = normalizer.fit_transform(X[:train_end_norm])\n",
        "X[train_end_norm:] = normalizer.transform(X[train_end_norm:])\n",
        "\n",
        "y = normalizer.transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v28K7FCIsyZ2"
      },
      "outputs": [],
      "source": [
        "dataset = DHWDataset(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cT7KkmMQts7y"
      },
      "outputs": [],
      "source": [
        "n = len(dataset)\n",
        "\n",
        "train = int(0.8 * n)\n",
        "val   = int(0.9 * n)\n",
        "\n",
        "train_ds = torch.utils.data.Subset(dataset, range(0, train))\n",
        "val_ds   = torch.utils.data.Subset(dataset, range(train, val))\n",
        "test_ds  = torch.utils.data.Subset(dataset, range(val, n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i16ME5Ixotnk"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_ds, batch_size=1, shuffle=False)\n",
        "val_loader   = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VazsOnwJovRc",
        "outputId": "492522a0-b167-4063-cdd2-435d8a7fb1f6"
      },
      "outputs": [],
      "source": [
        "# Validating all dimensions\n",
        "xb, yb = next(iter(train_loader))\n",
        "names_dim_X = [\"batch\", \"time\", \"channel\", \"latitude\", \"Longitude\"]\n",
        "names_dim_y = [\"batch\", \"time + 1\", \"latitude\", \"Longitude\"]\n",
        "\n",
        "print(\"xb shape:\", xb.shape)\n",
        "print(names_dim_X)\n",
        "print(\"yb shape:\", yb.shape)\n",
        "print(names_dim_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7KEI4Ybo0sI",
        "outputId": "c325b0e0-2149-44d2-f364-0403e9ecdfd9"
      },
      "outputs": [],
      "source": [
        "model = TemporalUnetTransformer().to(DEVICE)\n",
        "\n",
        "xb, yb = next(iter(train_loader))\n",
        "xb = xb.to(DEVICE)\n",
        "\n",
        "with torch.no_grad():\n",
        "    yhat = model(xb)\n",
        "\n",
        "print(yhat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN_ZR-5ho5BH"
      },
      "outputs": [],
      "source": [
        "# Model configs\n",
        "# Hiperparmeters\n",
        "learning_rate = 1e-4      # transformer + UNet -> lower LR\n",
        "batch_size    = 1\n",
        "epochs        = 50\n",
        "weight_decay  = 1e-5\n",
        "\n",
        "# loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# optmizer\n",
        "optimizer = torch.optim.AdamW(\n",
        "                              model.parameters(),\n",
        "                              lr=learning_rate,\n",
        "                              weight_decay=weight_decay\n",
        "                              )\n",
        "\n",
        "# scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                                                       optimizer,\n",
        "                                                       mode=\"min\",\n",
        "                                                       factor=0.5,\n",
        "                                                       patience=5,\n",
        "                                                       )\n",
        "\n",
        "# early stopping\n",
        "early_stopping_patience = 7\n",
        "early_stopping_counter = 0\n",
        "best_val_loss = float(\"inf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwzrEVrJX5KB",
        "outputId": "92fe52e3-6310-44b9-daf7-c5c06db8b5f4"
      },
      "outputs": [],
      "source": [
        "# Train Loop\n",
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(f\"\\nEpoch {epoch}/{epochs}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    train_loss = train_loop(train_loader, model, loss_fn, optimizer, DEVICE)\n",
        "\n",
        "    val_mse, val_rmse = eval_loop(val_loader, model, loss_fn, DEVICE)\n",
        "\n",
        "    # Scheduler --> validation loss\n",
        "    scheduler.step(val_mse)\n",
        "\n",
        "    print(\n",
        "          f\"Epoch {epoch} | \"\n",
        "          f\"Train MSE: {train_loss:.6f} | \"\n",
        "          f\"Val MSE: {val_mse:.6f} | \"\n",
        "          f\"Val RMSE: {val_rmse:.6f}\"\n",
        "          )\n",
        "\n",
        "    if val_mse < best_val_loss:\n",
        "        best_val_loss = val_mse\n",
        "        early_stopping_counter = 0\n",
        "        torch.save(\n",
        "                   {\n",
        "                    \"model_state\": model.state_dict(),\n",
        "                    \"mu\": normalizer.mu,\n",
        "                    \"sigma\": normalizer.sigma,\n",
        "                    },\n",
        "                   \"best_temporal_unet_transformer.pt\"\n",
        "                   )\n",
        "\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "\n",
        "    if early_stopping_counter >= early_stopping_patience:\n",
        "        print(\"Early stopping\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76rfczf3qKtN"
      },
      "source": [
        "# Test and Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy9isPFqobqs",
        "outputId": "e25971ad-33a6-4c4d-f4cf-0c6669eafa31"
      },
      "outputs": [],
      "source": [
        "# test\n",
        "ckpt = torch.load(\"best_temporal_unet_transformer.pt\", map_location=DEVICE)\n",
        "model.load_state_dict(ckpt[\"model_state\"])\n",
        "normalizer.mu = ckpt[\"mu\"]\n",
        "normalizer.sigma = ckpt[\"sigma\"]\n",
        "\n",
        "normalizer.mu = normalizer.mu.to(DEVICE)\n",
        "normalizer.sigma = normalizer.sigma.to(DEVICE)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "test_mse, test_rmse = eval_loop(test_loader, model, loss_fn, DEVICE)\n",
        "\n",
        "print(f\"Test MSE (normalized):  {test_mse:.6f}\")\n",
        "print(f\"Test RMSE (normalized): {test_rmse:.6f}\")\n",
        "\n",
        "# RMSE (units in days)\n",
        "test_rmse_phys = test_rmse * normalizer.sigma.item()\n",
        "print(f\"Test RMSE (physical units): {test_rmse_phys:.6f}\")\n",
        "\n",
        "# Baseline\n",
        "seq_len = 12\n",
        "all_times = ds.time[seq_len:]\n",
        "\n",
        "n_samples = X.shape[0]\n",
        "train_end = int(0.8 * n_samples)\n",
        "val_end   = int(0.9 * n_samples)\n",
        "\n",
        "test_times = all_times[val_end:]\n",
        "\n",
        "y_clim_list = []\n",
        "\n",
        "for t in test_times:\n",
        "    month = t.dt.month.item()\n",
        "    y_clim_list.append(clim.sel(month=month).values)\n",
        "\n",
        "y_climatology = np.stack(y_clim_list)  # (N_test, lat, lon)\n",
        "\n",
        "y_true_phys = []\n",
        "\n",
        "for idx in range(len(test_ds)):\n",
        "    _, yb = test_ds[idx]\n",
        "    yb = normalizer.inverse_transform(yb.unsqueeze(0).to(DEVICE))\n",
        "    y_true_phys.append(yb[0, 0].cpu().numpy())\n",
        "\n",
        "y_true_phys = np.stack(y_true_phys)  # (N_test, lat, lon)\n",
        "\n",
        "MSE_baseline = np.mean((y_true_phys - y_climatology) ** 2)\n",
        "print(f\"MSE baseline (climatology): {MSE_baseline:.6f}\")\n",
        "\n",
        "MSE_model = test_rmse_phys ** 2\n",
        "print(f\"MSE model (physical units): {MSE_model:.6f}\")\n",
        "\n",
        "Skill = 1.0 - (MSE_model / MSE_baseline)\n",
        "print(f\"Skill score: {Skill:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "UdecUMDQ2EFk",
        "outputId": "cbdc0b2d-4703-4190-c053-ab1112883e47"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "idx = 0  # zero-based --> 0 = january\n",
        "\n",
        "xb, yb = test_ds[idx]\n",
        "xb = xb.unsqueeze(0).to(DEVICE)\n",
        "yb = yb.unsqueeze(0).to(DEVICE)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_hat_phys = normalizer.inverse_transform(model(xb))\n",
        "    y_true_phys = normalizer.inverse_transform(yb)\n",
        "\n",
        "y_hat_map = y_hat_phys[0, 0].cpu().numpy()\n",
        "y_true_map = y_true_phys[0, 0].cpu().numpy()\n",
        "\n",
        "seq_len = 12\n",
        "all_times = ds.time[seq_len:]\n",
        "\n",
        "n_samples = X.shape[0]\n",
        "train_end = int(0.8 * n_samples)\n",
        "val_end   = int(0.9 * n_samples)\n",
        "\n",
        "test_times = all_times[val_end:]\n",
        "\n",
        "t = test_times[idx]\n",
        "\n",
        "lat = ds.latitude\n",
        "lon = ds.longitude\n",
        "\n",
        "da_pred = xr.DataArray(\n",
        "                       y_hat_map,\n",
        "                       dims=(\"latitude\", \"longitude\"),\n",
        "                       coords={\n",
        "                               \"latitude\": lat,\n",
        "                               \"longitude\": lon,\n",
        "                               },\n",
        "                       name=\"HWC_pred\"\n",
        "                       )\n",
        "\n",
        "da_true = xr.DataArray(\n",
        "                       y_true_map,\n",
        "                       dims=(\"latitude\", \"longitude\"),\n",
        "                       coords={\n",
        "                               \"latitude\": lat,\n",
        "                               \"longitude\": lon,\n",
        "                               },\n",
        "                       name=\"HWC_true\"\n",
        "                       )\n",
        "\n",
        "da_pred.attrs[\"time\"] = str(t.values)\n",
        "da_true.attrs[\"time\"] = str(t.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "xmuL8TyYCVQf",
        "outputId": "3ac6684d-ed17-4f81-e228-431861947078"
      },
      "outputs": [],
      "source": [
        "(da_true - da_pred).plot(\n",
        "                         cmap=\"coolwarm_r\",\n",
        "                         center=0\n",
        "                         )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
